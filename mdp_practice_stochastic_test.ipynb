{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import random\r\n",
    "\r\n",
    "# TODO: In \"for a in action[s]\" add wall\r\n",
    "# TODO: Plot delta over iteration for seeing how it smallens everytime\r\n",
    "\r\n",
    "states = []\r\n",
    "\r\n",
    "for i in range(3):\r\n",
    "    for j in range(4):\r\n",
    "        states.append((i+1, j+1))\r\n",
    "\r\n",
    "### Create reward dictionary\r\n",
    "rewards = {}\r\n",
    "\r\n",
    "for state in states:\r\n",
    "    # Green Terminal State\r\n",
    "    if state == (1,4):\r\n",
    "        rewards[state] = 1\r\n",
    "\r\n",
    "    # Red Terminal State\r\n",
    "    elif state == (2, 4):\r\n",
    "        rewards[state] = -1\r\n",
    "\r\n",
    "    # For all other states\r\n",
    "    else:\r\n",
    "        rewards[state] = 0\r\n",
    "    \r\n",
    "### Define actions\r\n",
    "# U = Up, D = Down, L = Left, R = Right\r\n",
    "actions = {\r\n",
    "    (3, 1): [\"U\", \"R\"],             # Start state\r\n",
    "    (1, 1): [\"D\", \"R\"],\r\n",
    "    (1, 2): [\"L\", \"R\"],\r\n",
    "    (1, 3): [\"L\", \"R\", \"D\"],\r\n",
    "    (2, 1): [\"U\", \"D\"],             # (2, 2) is wall so we can basically ignore it here\r\n",
    "    (2, 2): [\"U\", \"D\", \"L\", \"R\"],\r\n",
    "    (2, 3): [\"U\", \"R\", \"D\"],\r\n",
    "    (3, 2): [\"L\", \"R\"],\r\n",
    "    (3, 3): [\"L\", \"U\", \"R\"],\r\n",
    "    (3, 4): [\"U\", \"L\"]\r\n",
    "}\r\n",
    "\r\n",
    "### Define initial policy, here: Random\r\n",
    "policy = {}\r\n",
    "for state in actions.keys():\r\n",
    "    policy[state] = np.random.choice(actions[state])\r\n",
    "\r\n",
    "### Define Transition Probabilites\r\n",
    "p_action = {\"U\": 0.5, \"D\": 0.1, \"L\": 0.1, \"R\": 0.3}\r\n",
    "\r\n",
    "### Value Iteration Presetting ###\r\n",
    "# 0th Step: Set Hyperparams\r\n",
    "GAMMA = 0.9\r\n",
    "THETA = 0.005\r\n",
    "NOISE = 0.1\r\n",
    "\r\n",
    "# 1st Step: Initialize all V(s) arbitrary\r\n",
    "V = {}\r\n",
    "for s in states:\r\n",
    "    if s == (1, 4):\r\n",
    "        V[s] = 1\r\n",
    "    elif s == (2, 4):\r\n",
    "        V[s] = 1\r\n",
    "    else:\r\n",
    "        V[s] = 0\r\n",
    "\r\n",
    "# For Plotting\r\n",
    "delta_records = []\r\n",
    "\r\n",
    "\r\n",
    "def getStateFromRandomAction(a: Str, s: Tuple) -> Tuple:\r\n",
    "    if a == \"U\":\r\n",
    "        next_state = (s[0] - 1, s[1])\r\n",
    "            if next_state == (2, 2):\r\n",
    "                next_state = (s[0], s[1])\r\n",
    "\r\n",
    "    if a == \"D\":\r\n",
    "        next_state = (s[0] + 1, s[1])\r\n",
    "            if next_state == (2, 2):\r\n",
    "                next_state = (s[0], s[1])    \r\n",
    "\r\n",
    "    if a == \"L\":\r\n",
    "        next_state = (s[0], s[1] - 1)\r\n",
    "            if next_state == (2, 2):\r\n",
    "                next_state = (s[0], s[1])\r\n",
    "\r\n",
    "    if a == \"R\":\r\n",
    "        next_state = (s[0], s[1] + 1)\r\n",
    "            if next_state == (2, 2):\r\n",
    "                next_state = (s[0], s[1])\r\n",
    "    \r\n",
    "    return next_state\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "# Value Iteration\r\n",
    "numb_of_iteration = 0\r\n",
    "\r\n",
    "while True:\r\n",
    "    delta = 0\r\n",
    "    for s in states:\r\n",
    "        if s in policy:\r\n",
    "            v_init = V[s]\r\n",
    "            v_post = 0\r\n",
    "\r\n",
    "            # Get next state by altering the state tuple\r\n",
    "            for a in actions[s]:\r\n",
    "\r\n",
    "                a_rand = np.random.choice([action for action in actions[s] if action != a])\r\n",
    "\r\n",
    "                # If action is Up\r\n",
    "                if a == \"U\":\r\n",
    "                    next_state = (s[0] - 1, s[1])\r\n",
    "                    if next_state == (2, 2):\r\n",
    "                        next_state = (s[0], s[1])\r\n",
    "                    v = p_action[\"U\"] * (rewards[next_state] + GAMMA*V[next_state])\r\n",
    "                    if random.random() < NOISE:\r\n",
    "                        v = (1-NOISE) * (p_action[\"U\"] * (rewards[next_state] + GAMMA*V[next_state])) + (NOISE) * (rewards[])\r\n",
    "\r\n",
    "                # If action is Down\r\n",
    "                if a == \"D\":\r\n",
    "                    next_state = (s[0] + 1, s[1])\r\n",
    "                    if next_state == (2, 2):\r\n",
    "                        next_state = (s[0], s[1])\r\n",
    "                    v = p_action[\"D\"] * (rewards[next_state] + GAMMA*V[next_state])\r\n",
    " \r\n",
    "                # If action is Left\r\n",
    "                if a == \"L\":\r\n",
    "                    next_state = (s[0], s[1] - 1)\r\n",
    "                    if next_state == (2, 2):\r\n",
    "                        next_state = (s[0], s[1])\r\n",
    "                    v = p_action[\"L\"] * (rewards[next_state] + GAMMA*V[next_state])\r\n",
    "\r\n",
    "                # If action is Right\r\n",
    "                if a == \"R\":\r\n",
    "                    next_state = (s[0], s[1] + 1)\r\n",
    "                    if next_state == (2, 2):\r\n",
    "                        next_state = (s[0], s[1])\r\n",
    "                    v = p_action[\"R\"] * (rewards[next_state] + GAMMA*V[next_state])\r\n",
    "                                    \r\n",
    "                # If new value of v(s) is better than the old value, i.e. v_init, then keep it\r\n",
    "                if v > v_post:\r\n",
    "                    v_post = v\r\n",
    "                    policy[s] = a\r\n",
    "                \r\n",
    "                # Print information about the variables\r\n",
    "                print(\"s: {}, s': {}, a: {}, v: {}, v[s]: {}, V[s']: {}\".format(s, next_state, a, v, V[s], V[next_state]))\r\n",
    "                \r\n",
    "            # Safe highest state value v_post in V dictionary\r\n",
    "            V[s] = v_post\r\n",
    "            # Calculate delta, i.e. difference between the old value and the new value\r\n",
    "            delta = max(delta, np.abs(v_init - V[s]))\r\n",
    "\r\n",
    "    delta_records.append(delta)                                 # Optional (for plotting)\r\n",
    "    if delta < THETA:\r\n",
    "        break\r\n",
    "    numb_of_iteration += 1\r\n",
    "\r\n",
    "\r\n",
    "#########################\r\n",
    "\r\n",
    "print(\"Number of Iteration: {}\".format(numb_of_iteration))\r\n",
    "print(policy)\r\n",
    "print(V)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}